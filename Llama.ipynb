{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOD9qnluJstd961/KkyfdXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahilpate3345/gen-ai-/blob/main/Llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvAiXQZiFPbj"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install pypdf\n",
        "!pip install docx2txt\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "import os\n"
      ],
      "metadata": {
        "id": "XaDLvQHjGz6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "import os\n"
      ],
      "metadata": {
        "id": "eMeuDkcu4Sxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "ShsHmbDd4UnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers,!pip install google-generativeai,pip install llama-index-llms-gemini\n"
      ],
      "metadata": {
        "id": "tlt6iwh4x_P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "import os\n"
      ],
      "metadata": {
        "id": "IRpTuFn93rmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "hKe7ML853u4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all PDFs/DOCX in a folder\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "print(documents[0].text[:500])  # Preview first 500 characters\n"
      ],
      "metadata": {
        "id": "JyQM08Ubys2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "import os\n",
        "\n",
        "# Make sure your OpenAI API key is set in environment\n",
        "# Example for Windows PowerShell:\n",
        "# setx OPENAI_API_KEY \"sk-your_key_here\"\n",
        "# Example for Linux/macOS terminal:\n",
        "# export OPENAI_API_KEY=\"sk-your_key_here\"\n"
      ],
      "metadata": {
        "id": "OqVtNpcXy1NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "hlVMZbtz5Qwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/content\"))  # see whatâ€™s inside\n",
        "print(os.listdir(\"/bin/data\"))  # make sure your PDFs/DOCs are here\n"
      ],
      "metadata": {
        "id": "ra89GsdJ5Te0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade llama-index\n"
      ],
      "metadata": {
        "id": "eqWYdjpKMOku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "u-joOFxU6J6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain\n"
      ],
      "metadata": {
        "id": "TaHw-4ET6R39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers torch\n"
      ],
      "metadata": {
        "id": "dapK6-u-6kzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"langchain==0.3.27\" \"langchain-core<1.0.0\" \"langchain-text-splitters<1.0.0\" langchain-community llama-index transformers torch pypdf docx2txt"
      ],
      "metadata": {
        "id": "jou9z5UD6pkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "IcNWRyV764u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "qRazqLwO7Y6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCtuUjWTfg6S-oPsJH0mNansRlq8GACHmk'"
      ],
      "metadata": {
        "id": "YgGVfrj57cN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index llama-index-llms-gemini pypdf docx2txt transformers torch"
      ],
      "metadata": {
        "id": "posIX1J07kj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.gemini import Gemini  # Use Gemini wrapper only\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding  # or HuggingFace embeddings\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "2OZnSw5g8E6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index-llms-google-genai google-generativeai pypdf docx2txt transformers torch"
      ],
      "metadata": {
        "id": "GQ8iv0vt9DSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.8.0 torchaudio==2.8.0 torchvision==0.23.0 --force-reinstall\n"
      ],
      "metadata": {
        "id": "_0Q7nJ-fH4ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.readers.file import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "print(documents[0].text[:500])\n"
      ],
      "metadata": {
        "id": "LBhYvFy5PfVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.8.0 torchaudio==2.8.0 torchvision==0.23.0 --force-reinstall"
      ],
      "metadata": {
        "id": "h5vRNiniN2ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade llama-index llama-index-llms-google-genai google-generativeai pypdf docx2txt transformers torch"
      ],
      "metadata": {
        "id": "t_y1k5xk9PlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.google_genai import ChatGoogleGenerativeAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding  # or HuggingFace embeddings\n",
        "import os"
      ],
      "metadata": {
        "id": "0DBHNC929U7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini/PaLM model via Google GenAI\n",
        "llm = ChatGoogleGenerativeAI(model_name=\"gemini-1.5-t\")  # text-optimized model\n",
        "Settings.llm = llm\n",
        "\n",
        "# Set embeddings\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
      ],
      "metadata": {
        "id": "7BiDsZ_NB0QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/bin/data\").load_data()\n",
        "\n",
        "from llama_index.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "documents_chunks = splitter.split_documents(documents)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents_chunks)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Query example\n",
        "response = query_engine.query(\"Summarize this document in bullet points.\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "M7628yZQCZQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-base-en\")"
      ],
      "metadata": {
        "id": "aX1p7lu0HHXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm = llm, embed_model=embed_model, chunk_size = 800, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "mvxMNYqUHYKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context= service_context)"
      ],
      "metadata": {
        "id": "etQV-tp0HcPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "X11UF4OfHhJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is llamaindex?\")\n",
        "response"
      ],
      "metadata": {
        "id": "W395AvN3HjUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "cjJCjsQaHmrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "id": "debf2EjgHpiS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}