{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAJSGGIIH9yx"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain langchain-community\n",
        "!pip -q install pypdf\n",
        "!pip -q install sentence_transformers\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install faiss-cpu\n",
        "!pip -q install unstructured"
      ],
      "metadata": {
        "id": "O5LGqGtyIrKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4\n",
        "!pip install nltk==3.9.1"
      ],
      "metadata": {
        "id": "dMZmxYJtI0GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import textwrap\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "N5TZaLWnI2U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "FzOan7jNJFSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq python-dotenv\n"
      ],
      "metadata": {
        "id": "NQptOdvcKdDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "C2-oS2ZGJHmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLs=[\n",
        "    'https://blog.gopenai.com/paper-review-llama-2-open-foundation-and-fine-tuned-chat-models-23e539522acb',\n",
        "    'https://www.mosaicml.com/blog/mpt-7b',\n",
        "    'https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models',\n",
        "    'https://lmsys.org/blog/2023-03-30-vicuna/'\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "37yH-MJlKxmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = UnstructuredURLLoader(urls=URLs)\n",
        "data = loaders.load()"
      ],
      "metadata": {
        "id": "elzIQvAvLFu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "UyM0sxbBLKHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "BEn6H55JLPjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(separator='\\n',\n",
        "                                    chunk_size=1000,\n",
        "                                    chunk_overlap=200)"
      ],
      "metadata": {
        "id": "WTJ4LsuqLSAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "55_Woq4iLqyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "id": "C0roE62ZL3Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "id": "pxSP75hmL6SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[1]"
      ],
      "metadata": {
        "id": "GzFbxgdVMxHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[2]"
      ],
      "metadata": {
        "id": "Js3KrZHgM4VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "text = \"Groq provides low-latency inference for large language models.\"\n",
        "embedding = model.encode(text)\n",
        "\n",
        "print(len(embedding))  # 384 dimensions\n",
        "print(embedding[:10])  # first 10 values\n"
      ],
      "metadata": {
        "id": "MZhihU4fM8xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "IQycntmFNRXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-huggingface langchain-groq\n"
      ],
      "metadata": {
        "id": "X-oU6joXNpjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Hugging Face API token\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "-rIBqL7vO3Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEndpointEmbeddings(\n",
        "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ptY9UphIO6Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "\n",
        "print(\"Embedding length:\", len(query_result))\n",
        "print(\"First 10 dimensions:\", query_result[:10])\n"
      ],
      "metadata": {
        "id": "GgRNJGrgO8X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=FAISS.from_documents(text_chunks,embeddings)"
      ],
      "metadata": {
        "id": "qB8dJTLwPaD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain huggingface_hub transformers accelerate\n"
      ],
      "metadata": {
        "id": "imbHiJ6sRuru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain huggingface_hub\n"
      ],
      "metadata": {
        "id": "KgWhSNGkPoKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "EFAt4on7Rglw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface huggingface_hub\n"
      ],
      "metadata": {
        "id": "S8fAfn3ARkaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "EpXGD7RXQFLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-groq\n"
      ],
      "metadata": {
        "id": "TCI9mlvpQUPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n"
      ],
      "metadata": {
        "id": "3mOqC-j6VHBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Minimal LLM setup\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",             # Groq model\n",
        "    groq_api_key=os.environ[\"GROQ_API_KEY\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "NDdNeu6iVL_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Proper prompt format\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
        "\n",
        "# Invoke LLM\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "id": "GqC40vD_VRZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "R4z-woqpWrqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"please provide a conise summary of the book harry potter\")"
      ],
      "metadata": {
        "id": "7X7jDbokXAm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())"
      ],
      "metadata": {
        "id": "RaOaz4f2XLP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=chain({\"question\": \"How good is Vicuna?\"}, return_only_outputs=True)"
      ],
      "metadata": {
        "id": "iQyJbIudXcIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "4CwetRQ-XlPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_text=textwrap.fill(result['answer'],width=500)"
      ],
      "metadata": {
        "id": "t9Y88epqXvdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_text"
      ],
      "metadata": {
        "id": "E4yPDB0jX8vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "    query = input(\"prompt: \")\n",
        "\n",
        "    if query.lower() == \"exit\":\n",
        "        print(\"Exiting...\")\n",
        "        sys.exit()\n",
        "\n",
        "    if query.strip() == \"\":  # ignore empty queries\n",
        "        continue\n",
        "\n",
        "    result = chain({\"question\": query})\n",
        "    print(f\"Answer: {result['answer']}\")\n"
      ],
      "metadata": {
        "id": "C54snMdAYESo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}